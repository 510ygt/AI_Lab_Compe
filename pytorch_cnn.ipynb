{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHJSLwLyBjnp"
      },
      "source": [
        "# Pytorchを用いたCNNの実装\n",
        "\n",
        "## 概要\n",
        "\n",
        "機械学習用ライブラリPytorchを用いて、PythonでCNNを実装します。<br>\n",
        "今回は、CIFAR-10を用いた10クラス認識のモデルを設計し、学習させます。\n",
        "\n",
        "\n",
        "##  目次\n",
        "\n",
        "1. データの準備\n",
        "1. モデルの定義\n",
        "1. モデルの学習\n",
        "1. 学習記録のグラフ化\n",
        "1. モデルのセーブ・ロード\n",
        "1. モデルを用いたクラス認識予測デモ\n",
        "1. モデルの中間出力の可視化\n",
        "\n",
        "の順に実装します。\n",
        "\n",
        "## データの準備\n",
        "### 1. 1. ライブラリをインストールします。\n",
        "- torchsummary\n",
        "- tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UxIHg8e2Bjns"
      },
      "outputs": [],
      "source": [
        "#pip install torchsummary\n",
        "#pip install tqdm #conda install tqdmでも可\n",
        "\n",
        "#pip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 torchaudio==0.8.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "#pip install jupyterlab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "293RM_s3Bjnx"
      },
      "source": [
        "### 1. 2. ライブラリをインポートします。\n",
        "- pytorch(torch)\n",
        "- torchvision\n",
        "- numpy\n",
        "- matplotlib\n",
        "- PIL\n",
        "- tqdm\n",
        "- torchsummary\n",
        "- pylab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cTjjoBfyBjny"
      },
      "outputs": [],
      "source": [
        "import torch as torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "from tqdm import tqdm_notebook\n",
        "from torchsummary import summary\n",
        "from pylab import rcParams"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-I3-z91cBjn1"
      },
      "source": [
        "### 1.3. データセット内の教師画像(PILImage)の下処理、変換を定義します。\n",
        "- **torchvision.transforms**パッケージ内のクラスで行います。transforms.Composeでオブジェクトをまとめて返せます。  \n",
        "- transfoms.処理一例\n",
        "    - transforms.RandomHorizontalFlip(p=0.5), 50%で左右反転  \n",
        "    - transforms.RandomVerticalFlip(p=0.5) 50%で上下反転  \n",
        "    - transforms.RandomRotation(45) -45~45の範囲でランダムに回転  \n",
        "    - transforms.ColorJitter(brightness=0.5) 明るさをランダムに0.5倍～1.5倍  \n",
        "    - transforms.ToTensor()  PILImage -> Tensor, 0~1正規化  \n",
        "- pytorchではデータをTensor形式で扱います。(listやnumpyと似たような構造を持つ)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OtJ60dgnBjn2"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.ToTensor(), \n",
        "    ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ek4JZjJ0Bjn5"
      },
      "source": [
        "### 1.4. データセットのロード(画像(PILImage)と正解ラベルが格納されている))\n",
        "- 有名なデータセットは**torchvision.datasets**クラス内で定義されており、簡単に利用できます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "8d33bbf004524bfa83982c489c6bfefa",
            "056b1a5f2c3340edbdf2d7c9b094c8dc",
            "76746f7c45754c57ab78ea081107b4c1",
            "b317994d1c664e45931b198c4a0801e3",
            "da2b2f4c59b94d868c1064e56fca8a73",
            "7074fa6a34564802ab1239a254f90bf6",
            "d36b415a75e344eb8774763b86956b51",
            "5291cc5a45484153900e7c9658477e75"
          ]
        },
        "id": "6Nt5WZFvBjn6",
        "outputId": "932639ea-9372-433e-8b56-b32bc06b2f16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./dataset/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8d33bbf004524bfa83982c489c6bfefa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=170498071.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ./dataset/cifar-10-python.tar.gz to ./dataset/\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "train_dataset = torchvision.datasets.CIFAR10(root='./dataset/',\n",
        "                                             train=True, #訓練データをロード\n",
        "                                             transform=transform,#上で定義した変換を適用\n",
        "                                             download=True)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./dataset/',\n",
        "                                             train=False, #検証データをロード\n",
        "                                             transform=transforms.ToTensor(),\n",
        "                                             download=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HEb72ciBjn9"
      },
      "source": [
        "### 1.5. データセット可視化用に画像(PILImage or Tensor)を壁画する関数を定義します。\n",
        "- データセットの入力画像(PILImage)をtorchvision.transforms.ToTensor()でTensor型に変換したものを出力します\n",
        "- 画像を表示するplt.imshow関数の引数の入力画像サイズは(H,W,C)なので(C,H,W)を**np.transpose(numpy,(並びの指定))**で(H,W,C)に変換します"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ux82OL41Bjn-"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "def show(img):\n",
        "    npimg = img.numpy() \n",
        "    plt.grid(False) \n",
        "    plt.imshow(np.transpose(npimg, (1,2,0)))\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJFiltYYBjoC"
      },
      "source": [
        "### 1.6. データセットの可視化"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "iMwzNN_IBjoD",
        "outputId": "fc04115a-9ecb-46a5-aae7-31ed8114dd44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset CIFAR10\n",
            "    Number of datapoints: 50000\n",
            "    Root location: ./dataset/\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               RandomHorizontalFlip(p=0.5)\n",
            "               ToTensor()\n",
            "           )\n",
            "学習画像サイズ torch.Size([3, 32, 32])\n",
            "ラベル: 9\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2da4xdV5Xn/+u+b72frio/y88kDnlAakICaRQejdKABEg9CISYfECd1kwjDZqeD4iRBkaakejRAOLDiFEYog4thkATGNIjNJDOtDoDk47jvBzHjh3HLr9dtsv1cj3uc82He6120vu/qxK7bhnO/yeV6tZetc/Zd5+z7rln/89ay9wdQojff1JrPQAhRGuQswuREOTsQiQEObsQCUHOLkRCkLMLkRAy19LZzB4A8B0AaQD/3d2/Efv/fD7nxbZi0JaKfOyYkXakaZ9qtRaxVSP74gNJpcIDyWR4Hzb2ho0b02l+aArF8BwCQIqOn++rWGyjNouMo1Raorb5y3PBdq/XaZ96jR8zB5eILc3Pg1w+PFeFYgcfR53vq1YpU1s5Mh+VMreZhfeXyRVon1whfMwmz09gbnYmeLDfsbObWRrAfwXwhwBOAXjOzJ5w9wOsT7GtiPs/eE/QVijykzGTDbenrZP2mbp0mdouXLjE95XOU1tHW3jy+/q5s2Rz/ATO5/i+unoGqG33rbdRWy4bHmMqlaN9bn3Xu6mt0N1HbUcOv0Zte377dLC9urRA+8xOzVBbLc0/oLOd3HG37Lg92L7r1vfRPkuLfF9T505Q24k3DlLbxAk+V2ny3ga33kL7bLz5rmD7f/o3/4r2uZav8XcDOOLuR929DOAxAJ+8hu0JIVaRa3H2DQBOXvX3qWabEOIG5Jru2VeCmT0E4CEAKBb5PYgQYnW5liv7aQCbrvp7Y7PtTbj7w+4+5u5juTy/bxRCrC7X4uzPAdhpZlvNLAfgswCeuD7DEkJcb97x13h3r5rZlwD8Cg3p7RF3fzXap17H0tJi0FZ3vhrf398TbI9JaPkCf2vFNv4No7srvC8AKBbCMk42H1MS+Gp8ucr7rV+/ldo+8uEHqK1AxpjJ8Pcck/li/Ya6+Sr+zi3rg+1nTp+ifU4eOU5tJ04eobaJaa6uLE1NBtvrC7xPyvl81OoVahvZvI3avF6iNqvOBtv7e7gSMjsVHn8tIl9e0z27u/8SwC+vZRtCiNagJ+iESAhydiESgpxdiIQgZxciIcjZhUgIq/4E3dW4O6rVcNRQRDHAVCosTbS3t/N9gUskAI9c6uriEWXFQjjwZmZ2ivbJ5XmQTCpLInwAbN+2m9p6e9ZR2xIJNJmbC0ehAUA+Mo6u9i5qy0Qku8H14Sen2/siAT63hIM7AGBm5gK1nZ7gct6FyfC5A3DZlp2jAHBxko+DBSEBwNAwf5J8/PDFYHu5xM9hSxFbJIGsruxCJAQ5uxAJQc4uREKQswuREOTsQiSElq7GmwGZTHiXpRJfAa2RhdN6JCihq4uvgs/O8vRHUzPhlVEAqHn4s5HlAwOAhUU+xs2bRqktl+Or4AdePUxt5Uo411lPL1cuBvr6+fbKXCZ5es9z1PbcwXB2sptuu4P2ydZ50E1bG78uDY9spLaejWSFnOU6A1CJ5Jlrj+RkOBEJ5Jk8N0Ft+VxYAapH8ig6CSiL5fjTlV2IhCBnFyIhyNmFSAhydiESgpxdiIQgZxciIbRUektn0ujp6Q7aJid5MEmlEtbeJi+xIAdgZHiY2gYHeW6vhXmeK6xWD48j38YrkhTSPLAmk+UVYV54cR+1feC+u6mtp7c32D48zANQSPWhhi1SIeel/bzKyV/95PFg+yfqkVOuzvc1GwmEGRkOv2cA6O8Jy4odPTzXYFcbl1J3beQy37YNm6jt5NHXqe2Fl18Ktsfy/11emA+2S3oTQsjZhUgKcnYhEoKcXYiEIGcXIiHI2YVICNckvZnZOIA5ADUAVXcfi/4/UshkwvJKZyeP8pqdDUtsxQKPXMqk0tRWKnF5rV7m0gWyYVu5zj8z12+MSF4lLh2O7riZ2nbfvpPamIpWq3J9rRIpo3Xs5DFqm5vm4+8iRTznL56jfdYNb6e287PhaD4AmCiHSzwBwPSZcO69SuSYVWp8rvavH6K2vn4uwXZ38Gi5xSLJKWi8PFg+H46Is1SkFBm1rJwPujuPCxVC3BDoa7wQCeFand0B/NrMnjezh67HgIQQq8O1fo2/z91Pm9k6AE+a2Wvu/vTV/9D8EHgIANra+aOjQojV5Zqu7O5+uvn7PICfA/gnD227+8PuPubuY4U8f/ZZCLG6vGNnN7N2M+u88hrARwHsv14DE0JcX67la/wQgJ9bQx7IAPgf7v6/Yx3q9ToWFsLliaoR+YdFyuWzPCHf5Vle7gjgkl1piUs81Up4m8VsuCwUACzOXqK2zjSX+bq7+LegVIbLK6UlEiE4yZNsHj7EE1geP8alN0TKJN20/aZg+/iJM7TPq4cOUdvsZGQe27nk1UMk3WKeS721iCy3eJnLfOk8P6/qJHITANKZcGTejk08im5dT1gCTKW4S79jZ3f3owB4qlAhxA2FpDchEoKcXYiEIGcXIiHI2YVICHJ2IRJCSxNO1r2OUilco6pY5E/XtbeHEwDOTJ2nfcqRyLbh4fXU1tnBJZkUwuPId/KEh1v6+fu6/ebN1NY7Mkht1UgE27Fj4Xpjr7xykPaZmebJPicnuFR2cvw0te24495ge36Jy6Unx1+mtpkpLnkdHX+D2qqlcK29nkjNtp5OLuV5il8fO7pI9BqA7nZ+jixUwtGD64jkDAC7tu0KtqfT3KV1ZRciIcjZhUgIcnYhEoKcXYiEIGcXIiG0djW+Xsc8KVuTL/DAj3IlHHAxcY5nwypGtjdHctoBQDbLp2R4KBzwcs/dt9M+XdVpanv1H56htvev301tdb6gjfnLYbVjaB0vh7Vv36vUdvAAL0O1OBM+lgAwetv7wuNYz/Pn3X7rndQ2N8mVl+Nv8GCdC+cmgu1bBttpn5FBrqDsP8gDOw+/fpbazo1zVSPdGR5LvpMHz/R2hM+rUokfE13ZhUgIcnYhEoKcXYiEIGcXIiHI2YVICHJ2IRJCS6U3r9dRKoVz0M3O8rxqg4PhoJBYQEulzANhZmZ5PrbtO0ap7bbbtwXbh/rDpY4AYP+vXqC2Q/u4rPWeD4XnCQA88hm9a9ctwfajb4zTPsdO8ICWE+d5kExvhudc83JYNpqf48el0tlHbel0D7VlsrzfwGA4eGl4iJfl2jTCpbdRklsPAA4dPkVtBw+8Tm2LufDxTGW59PYPTz8ZbJ+/zGVlXdmFSAhydiESgpxdiIQgZxciIcjZhUgIcnYhEsKy0puZPQLgEwDOu/u7mm19AH4MYBTAOIDPuDvXaK7sLJvB0FA4T1dXF8/9lsuFI9i62sJlcwDgxHEeCbVhA5fsPvqR+6lt08ZwHrHFqcu0TyHN88WNruflfToKfD7Aq0ahUUU70MX5OFI5HgFWj5RJ6ujg/bwWHmSN5CAEgEqV22rOJbt0hk9IzcIhghcvcIlqdvICtW3awWW+9ZtGqc3SvN8lEsVYKvFxvLj3t8H2CpE8gZVd2f8SwANvafsKgKfcfSeAp5p/CyFuYJZ19ma99bdW1fskgEebrx8F8KnrPC4hxHXmnd6zD7n7lUj9c2hUdBVC3MBc8wKduzvYjSIAM3vIzPaa2d4yyeEthFh93qmzT5jZCAA0f9OcQe7+sLuPuftYLlK/WgixurxTZ38CwIPN1w8C+MX1GY4QYrVYifT2IwD3Axgws1MAvgbgGwB+YmZfBHAcwGdWtLN0Gj2d4eilWo1LBplMeJiFPC+pc9cYX0YYu2OU2vra09Q2efposD2XDkdWAUCxg0fELVzmtlSkjI9F5qpu4Wg5z/H3lS7yecy1c4mqo5/LSfVUePwpCycPBYAauLy2VOFRgLnIWZxvC89xZyQhaSrFj8vcEt9XIc0lwHnn73t6Opw8sqvAI0HbOsJznyLzDqzA2d39c8T04eX6CiFuHPQEnRAJQc4uREKQswuREOTsQiQEObsQCaHFtd4ci/NheaVc4ZpGWzEsbW3fFU5ECQA3bd9CbV7i9ddmL/D6cR2dZLrqXHK5PD/Hx5Hmn7WpLJfKajVe7K2OsCyX4ptDscgTLFqdj7Fc4RJgoRieq2JfgfZpi0Q+XibnDQDUMlxGq5bD51Wtwuew2NFBbQtVLodlS3yuJmZ5ZOTSUrg+W3cbn4+RzVuD7QcOvkz76MouREKQswuREOTsQiQEObsQCUHOLkRCkLMLkRBaKr1VK1VcmAhLW4MD3bTffe8dC7aPkgSQADB7idfdsiqXjPq6uOySI1FIMzNcFspleQRVoY9Hy1lMeotknKzXw2OsVXnUFSIRZUNdndS2bcsItW0YCfcrRo5zuoNLgPkST245G4kou7AUjtqbm+OS6PTsW7Ow/SNtkfnIlbkE6DU+xgUylkonPz/cwueHc2VQV3YhkoKcXYiEIGcXIiHI2YVICHJ2IRJCS1fjM5k0BteFV9A/9fGP0H5DA+GAgPnpc7RPIceXJTt6+Ip7pcRXTbOp8GprildWQi7HV+MzhchqayRwhSy4N7aZCe+vr5cHVXz0w/dS2+wlHqC0fWu4lBcA3HxLOFCjoyecgxAA6pHglJNdfJIPVWlyY4xkwiv8hbZh2qe9i4+x5pGgpyVevuq16iS11Umav0w9oqAwdSVW5otvTQjx+4ScXYiEIGcXIiHI2YVICHJ2IRKCnF2IhLCS8k+PAPgEgPPu/q5m29cB/AmAC81/+6q7/3K5bXV0tuO+P/hnQdvgAJehauVwzrhUimtQpQqvGNuR5Z9xZnybqUy4Xz2Si815gVuks3z6Pc3HUanz/aXTYc2up5sHcHzk/vdS2/jhcWo7d/4EtfV23Rpu7+QSYK3MpaviFl7Oa/0Al1K9Hp7/fJafb52kRBkA1Iwfz3MXuAQ43MODfE5vXB9sX79hA+1z9ED4Pe955m9pn5Vc2f8SwAOB9m+7+53Nn2UdXQixtizr7O7+NAAe8yeE+J3gWu7Zv2Rm+8zsETPjgeVCiBuCd+rs3wWwHcCdAM4C+Cb7RzN7yMz2mtney5d5kgQhxOryjpzd3SfcvebudQDfA3B35H8fdvcxdx/r6OCLIkKI1eUdObuZXZ2P6NMA9l+f4QghVouVSG8/AnA/gAEzOwXgawDuN7M7ATiAcQB/upKdpQxoI3ncvMJzgrURyeu3v+GfMVu2bqK2wYF+aktluORVI5JXeZFLRnUi/QBALSLz1SPRS9VI+adalURlOZfrqnV+ezUwwHO/tXdtprZSKTwntYgkWnV+7WnvGaC2zj4efcdi1IwHr/E5BFCt8fEPDnF5cChim58Jh70Vi1xS7M2E8x62tXGJb1lnd/fPBZq/v1w/IcSNhZ6gEyIhyNmFSAhydiESgpxdiIQgZxciIbQ04WTKgDaSnbG3wEvnnDoULuXkE1zyah/hGRsLJf4ZVyFRYwBgKSJ5RUorxaLeapkstaEWySpZjWyzHpaNDJHtgb9nz/MxdrT18X5GIgQjmlc1UtYqFZEwq1Uuh4HIm6k0Pwcy2VjkI58PjyV7jEx/MROOsrM6Py7F9rAkmkrx96UruxAJQc4uREKQswuREOTsQiQEObsQCUHOLkRCaKn0lk6l0N0Zlgw8kkRxcWE+2L5lM48k6urkUl69Fo4YAgBL84iyOqm9tbR4mfbxSL2uzs4CtaXA5yOVikhUFj6k6RSvObdU5mOcnp6htrmZcCJQAJi7FO6XiUhDbe08KWZbG8+FkM3y95bNhqWyDImkBIB8RG7MRfbV3sEjBPN53s/IMWvL8/Ojszsse7KEo4Cu7EIkBjm7EAlBzi5EQpCzC5EQ5OxCJISWrsZnMmn09YXL/6TB86Bt3r4x2J41vvLY3cdXdku+RG31yCp4rRq2xVZAe7t5uaPOQiSoosbHODFxltqOHT0dbD918hzvc4yXcZqdm6S2WD65k8eOB9u7OnhetV07b6G29j5ekqlU48ds6mJ4/JcipZrSkaiVWC652Ip7PRII09Edzq/X28v3la6EFaDp6XA+O0BXdiESg5xdiIQgZxciIcjZhUgIcnYhEoKcXYiEsJLyT5sA/ADAEBrlnh529++YWR+AHwMYRaME1GfcfSq+LSBL9sjFK6CrPyyj1Um+NQCoRAJaKpVIsEtkHJYKB9esWxeWBgEgFynVVIqUO7JIWrXXDr5ObY//9OfB9ukZHqwz0M9LK+3auZ3atm7eQm31994bbI8Fd8T0qaf2PENtvRu4RLVUCwf5nDp1hvbJpCL5C/M82OXiJJcpj58K51EEgHe/74PBdjvL5dfpU4eC7bNz/Div5MpeBfDn7r4bwD0A/szMdgP4CoCn3H0ngKeafwshblCWdXZ3P+vuLzRfzwE4CGADgE8CeLT5b48C+NRqDVIIce28rXt2MxsF8G4AzwIYcvcrj3KdQ+NrvhDiBmXFzm5mHQAeB/Bld3/TM3neSJgdTJptZg+Z2V4z2zs1ze8nhBCry4qc3cyyaDj6D939Z83mCTMbadpHAAQfNnb3h919zN3Henv4c9FCiNVlWWc3M0OjHvtBd//WVaYnADzYfP0ggF9c/+EJIa4XK4l6ez+ALwB4xcxearZ9FcA3APzEzL4I4DiAzyy3ITMglyXilnOJKpUOl9WxFI8aS0VzcfEyPfk0n5Lj42G5Zs+v99I+24bXUVu9wGWo0eJuauvr3UBtn//8vwi2b9m6nvZZt46XcSpk+BgzpMQTAJAqX2iPSG8Lc7yc17kSV3Xbhvuprb8/HHV4/PBR2ieXKlJbPs+/nY4M8zx5kzM8qvPDfxRe227rHKZ9SufD8uuhQy/QPss6u7v/BqCFwj68XH8hxI2BnqATIiHI2YVICHJ2IRKCnF2IhCBnFyIhtDThpLuhXA1Hji0s8KfrKkth28w8Dw1bXOARQzNTvKTRzCyXSF4n0WZnDoaTKwLApeFI0sAclw5PTvFElWMf/zS1zZbDiRSf+e3/pX02buSy3PwsL5U1M3WJ2uZmw4kPuzu6aZ/eTp4k9NSJY9Q2lOYJJyvkvCpESjx5lUffTZIElgDQESn/1HjINMyBA/uD7V3dF2mfXcNhedAiiS11ZRciIcjZhUgIcnYhEoKcXYiEIGcXIiHI2YVICC2V3srVFE5dDEc9/eJxLg2dOj4ebJ+LSG+1EpeMKmUeYTdf5ZKMeVjiaYtE0c28cYHauvJhGRIAMpM8weItf3AftX3/e98Ntu998XnaZ+sor7G2fniU2nIFfq3o7w9Hom3fziPs2kliUQCwGo+W+/Vf/4raypXweTA3PU/7IJII9MLFiMtE5LWFKj9Xf/7YD4Ltm4Z5ItORP/54sL0e2Y+u7EIkBDm7EAlBzi5EQpCzC5EQ5OxCJISWrsZXa8CF6fCT+s+9zMvjnD0dzv2WZYnOABTSPCJgYIAHp2zbuoPa+obD5Y4WLvPcaZVyuPwQAMxM87xq69fz/GMHDh+mtv2HXwu2p4s8P9pSZPV5KbLCPH7kDWp7T1s4V9vN226mfbpGeG69nqFt1FYCX8U/c+Z0sH1wiAdKlZf4Sr2l+HlVr/HiYbXIPFbr4fnfObqV9hkZGgm2Z7M52kdXdiESgpxdiIQgZxciIcjZhUgIcnYhEoKcXYiEsKz0ZmabAPwAjZLMDuBhd/+OmX0dwJ8AuBLp8VV3/2VsW3Nz8/g/f78naFuo8KCQgQ03BdtnL47TPr29vExPRyfP7zY9y3PhbdzaS/a1mfZZIIEYANC1kedOSxm3Pfn3v6G2Mvn8TuX4/CJSkulyhUuHZ86fo7aeI+H5f+PgIdqn7wIPGvICD1C65647qK14773B9myOlwerIVKKLFLyql7n0ls1IsuVSuH91Zd4UMulC+H8f9UqP29WorNXAfy5u79gZp0AnjezJ5u2b7v7f1nBNoQQa8xKar2dBXC2+XrOzA4C4E8/CCFuSN7WPbuZjQJ4N4Bnm01fMrN9ZvaImYW/4wohbghW7Oxm1gHgcQBfdvdZAN8FsB3AnWhc+b9J+j1kZnvNbO/SEn+sVAixuqzI2c0si4aj/9DdfwYA7j7h7jV3rwP4HoC7Q33d/WF3H3P3sUKB170WQqwuyzq7mRmA7wM46O7fuqr96ifxPw0gXNZCCHFDsJLV+PcD+AKAV8zspWbbVwF8zszuREOOGwfwp8ttyMHTdK0b4fm2cvlwJM/spXBEEwCUK1w+ybfxMj11j0SHzYXLRtXmuVx3ucqlN4uUIKpG6vhcnOTlq9Lp8Len4cj8wrgs19vdQ21jd41RW0cmLOfNXw6XhQKAoTyfqw0jXN48MxUueQUAxw6GIyarKT73KHApsreXz0c2y7c5cZ6Xcjp/Phz9ePstt9I+PV3hY5aKROWtZDX+NwBCW4hq6kKIGws9QSdEQpCzC5EQ5OxCJAQ5uxAJQc4uREJoacLJQi6LHVvXB235Ah9KgSQvPHX0pWA7ACASNWZpLpGMbookNlwK64alRZ6g8HLkqUFb5JFXuRyXfzLgSQWH+8OJCD/7zz9P+7z6Co9EK0WkssHRUWqbmgzLSeemuAR128ZN1LZ9B7ctngjLawDwN//zb4Ltx8dP0j5V8Ai1QpE/GJbN8nN4diFyHmTDx/qmrTwEJd8/EGyPKG+6sguRFOTsQiQEObsQCUHOLkRCkLMLkRDk7EIkhJZKb+VSCSfeCMs8Z87zZIPF9nCUWq3M63Xtvuvd1GYkMgwAhiPyz6FDR4Pt1UiiwZpxeS0Vmf6FRf7eUnWeiLBIEkuWI9tbP8xr3z33/3g9tz3P8sSX/YODwfb33ROWXgHg3CKXS5/Zx+vbzYPP8W13vz/YvvPWBdqnVuVJNq0WSUaZ5tfOWkSWS+VIFGaKb29hMTz+WNJLXdmFSAhydiESgpxdiIQgZxciIcjZhUgIcnYhEkJLpTd3h5NEkKW5adrvzPjrwXaWABIAntv7IrUNbd5ObT0b5qjtyOFwAt3qEpdxsnmewDJPovkAoL2dR7119fAEkbliWMaZnOLS5uTFcIQaAGTb+L761w1T2+C6dcH27bt20D7rRsKRXADQyFgeJr3A5/+W3TcH21MFPvelhYj0tsij18rO+y1FIunyeZI8sszfV3tHOPIxlnBSV3YhEoKcXYiEIGcXIiHI2YVICHJ2IRLCsqvxZlYA8DSAfPP/f+ruXzOzrQAeA9AP4HkAX3CPLEcCKBQK2LUrvDq6eQsPQLl44Vyw/fyFCdrn9Dm++lwu8WG+uv8Vajt5PKwK1Eo8B106x4NuYqvxXd1d1NbWxlfqO1PhQ3r2zFnaZ3z8GLUN9PFx3Hln+FgCQKUaDmpZWuQr/90dPOdaJMYEpXmu5MxPh0tDnbkYPpYAcJGUYwKA8gzf11KVr9Tv3D1KbRu3dAfba3VeVmxhLry6X69HAqio5R8pAfiQu9+BRnnmB8zsHgB/AeDb7r4DwBSAL65gW0KINWJZZ/cGVz5iss0fB/AhAD9ttj8K4FOrMkIhxHVhpfXZ080KrucBPAngDQDT7n7lu9opAPw7mBBizVmRs7t7zd3vBLARwN0A+M3aWzCzh8xsr5ntnV/g97ZCiNXlba3Gu/s0gL8DcC+AHjO7shq0EUCwWLq7P+zuY+4+1h6piy6EWF2WdXYzGzSznubrIoA/BHAQDaf/4+a/PQjgF6s1SCHEtbOSQJgRAI+aWRqND4efuPv/MrMDAB4zs/8I4EUA319uQ6lUGh0dnUFbRye/6g/09wfbd+7kdxPlSK6wS7P8duLMRCQXHu4Itk9NclnrzAQvdzQzd4nbpiepLVyEqkF7V2+wvbOXy5TVGpcizxx/jdpeMT6SYls4AOj8GS7znTkSDjQCgPYClxuLRW7r7g7LWnue2Uv77NnzPLV5pURtw0M8kOeuOzZTW6YSluy8ymW0OgusqfNjsqyzu/s+AP8ke6O7H0Xj/l0I8TuAnqATIiHI2YVICHJ2IRKCnF2IhCBnFyIhmHtMyLnOOzO7AOB4888BAFyXah0ax5vRON7M79o4trh7sPZWS539TTs22+vuY2uyc41D40jgOPQ1XoiEIGcXIiGspbM/vIb7vhqN481oHG/m92Yca3bPLoRoLfoaL0RCWBNnN7MHzOyQmR0xs6+sxRia4xg3s1fM7CUz42FQ13+/j5jZeTPbf1Vbn5k9aWavN3+Hw9dWfxxfN7PTzTl5ycw+1oJxbDKzvzOzA2b2qpn962Z7S+ckMo6WzomZFcxsj5m93BzHf2i2bzWzZ5t+82MzC9eAYrh7S38ApNFIa7UNQA7AywB2t3oczbGMAxhYg/1+AMB7AOy/qu0/A/hK8/VXAPzFGo3j6wD+bYvnYwTAe5qvOwEcBrC71XMSGUdL5wSAAehovs4CeBbAPQB+AuCzzfb/BuBfvp3trsWV/W4AR9z9qDdSTz8G4JNrMI41w92fBvDWYPZPopG4E2hRAk8yjpbj7mfd/YXm6zk0kqNsQIvnJDKOluINrnuS17Vw9g0ATl7191omq3QAvzaz583soTUawxWG3P1KFoxzAIbWcCxfMrN9za/5q347cTVmNopG/oRnsYZz8pZxAC2ek9VI8pr0Bbr73P09AP4IwJ+Z2QfWekBA45Md8YQ0q8l3AWxHo0bAWQDfbNWOzawDwOMAvuzus1fbWjkngXG0fE78GpK8MtbC2U8DuLr8C01Wudq4++nm7/MAfo61zbwzYWYjAND8HS5lssq4+0TzRKsD+B5aNCdmlkXDwX7o7j9rNrd8TkLjWKs5ae77bSd5ZayFsz8HYGdzZTEH4LMAnmj1IMys3cw6r7wG8FEAPAna6vMEGok7gTVM4HnFuZp8Gi2YEzMzNHIYHnT3b11laumcsHG0ek5WLclrq1YY37La+DE0VjrfAPDv1mgM29BQAl4G8GorxwHgR2h8Haygce/1RTRq5j0F4HUAfwugb43G8VcAXgGwDw1nG2nBOO5D4yv6PgAvNX8+1uo5iYyjpXMC4HY0krjuQ+OD5d9fdc7uAXAEwF8DyL+d7eoJOiESQtIX6IRIDHJ2IRKCnBHR7v0AAAAhSURBVF2IhCBnFyIhyNmFSAhydiESgpxdiIQgZxciIfx/L20WFnu7wScAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light",
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "print (train_dataset)\n",
        "image, label = train_dataset[1]\n",
        "print(\"学習画像サイズ\",image.size())\n",
        "print (\"ラベル:\",label)\n",
        "show(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFvZRjDUBjoH"
      },
      "source": [
        "### 1.7. データセットをミニバッチ単位に変換します。\n",
        "- **torch.utils.data.DataLoader**クラスで行います。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HhV3WIsBjoI",
        "outputId": "567b92ee-6708-4e51-880c-e9941906c0ee"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ],
      "source": [
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=64, #バッチあたり64枚\n",
        "                                           shuffle=True,\n",
        "                                          num_workers=4)#4プロセスでデータをロード\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                           batch_size=64, \n",
        "                                           shuffle=False,\n",
        "                                         num_workers=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKkA-yOtBjoL"
      },
      "source": [
        "## 2.モデルの定義\n",
        "### 2.1. モデルの定義(nn.Moduleを継承したクラスでの書き方)\n",
        "- **__init__**関数でネットワーク層の定義、初期化を行います。\n",
        "- **forward**関数でモデルの入力→出力の定義、順伝搬の計算を行います。  \n",
        "    - 定義したネットワーク層に入力(x)を伝搬していきます。\n",
        "- 全結合ネットワークは**nn.Liner(入力パラメータ数、出力パラメータ数)**で定義します。\n",
        "    - 画像データを扱う場合、入力パラメータ数は**二次元データを一次元に変換**して入力します。\n",
        "    - Tensorのサイズ変換には**Tensor.view(軸について要素数を指定)**を用います。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzRLSUVkBjoN"
      },
      "outputs": [],
      "source": [
        "num_classes = 10#出力クラス数\n",
        "\n",
        "class AlexNet(nn.Module):\n",
        "    \n",
        "    #畳み込みブロック(プーリングなし)\n",
        "    def conv_block(self, in_dim, out_dim):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_dim, out_dim, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(out_dim),\n",
        "            \n",
        "        )\n",
        "    #畳み込みブロック(プーリングあり)\n",
        "    def conv_block_pooling(self, in_dim, out_dim):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_dim, out_dim, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(out_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "        )\n",
        "    \n",
        "    def __init__(self, num_classes):\n",
        "        super(AlexNet, self).__init__()\n",
        "        #畳み込みブロック群\n",
        "        self.block1=self.conv_block(3,96)\n",
        "        self.block2=self.conv_block_pooling(96,256)\n",
        "        self.block3=self.conv_block(256,384)\n",
        "        self.block4=self.conv_block_pooling(384,384)\n",
        "        self.block5=self.conv_block(384,256)\n",
        "        #全結合ブロック群\n",
        "        self.classifier= nn.Sequential(\n",
        "            #6ブロック(ここから全結合層)\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(256*8*8,1048),\n",
        "            #7ブロック\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(1048,1048),\n",
        "            #8ブロック(出力)\n",
        "            nn.Linear(1048,num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        #1-5ブロック\n",
        "        x=self.block1(x)\n",
        "        x=self.block2(x)\n",
        "        x=self.block3(x)\n",
        "        x=self.block4(x)\n",
        "        x=self.block5(x)\n",
        "        #(N,C,H,W)→(N,C*H*W)\n",
        "        x = x.view(x.size(0),256*8*8)\n",
        "        #6-8ブロック\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "    \n",
        "    \n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "net = AlexNet(num_classes).to(device)#モデルをインスタンス\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IL3Vw4hm-IX0"
      },
      "outputs": [],
      "source": [
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(AlexNet, self).__init__()#おまじない\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=5),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        self.classifer = nn.Linear(256, num_classes)\n",
        "      \n",
        "        def forward(self, x):#ここで以前までの定義した関数を組み立てる\n",
        "            x = self.features(x)\n",
        "            x = x.view(x.size(0), -1)\n",
        "            x = self.classifier(x)#全結合層を実装\n",
        "            return x\n",
        "\n",
        "print(AlexNet())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLrQHdL7BjoQ"
      },
      "source": [
        "### 2.2. モデルの可視化\n",
        "- **summary(モデル,入力サイズ(チャンネル数、パラメータ数))**クラスで可視化を行います。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAHTUjZrBjoQ",
        "outputId": "23bdc152-0b95-4af7-d568-13dd8947bf83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 96, 32, 32]           2,688\n",
            "       BatchNorm2d-2           [-1, 96, 32, 32]             192\n",
            "              ReLU-3           [-1, 96, 32, 32]               0\n",
            "            Conv2d-4          [-1, 256, 32, 32]         221,440\n",
            "       BatchNorm2d-5          [-1, 256, 32, 32]             512\n",
            "              ReLU-6          [-1, 256, 32, 32]               0\n",
            "         MaxPool2d-7          [-1, 256, 16, 16]               0\n",
            "            Conv2d-8          [-1, 384, 16, 16]         885,120\n",
            "       BatchNorm2d-9          [-1, 384, 16, 16]             768\n",
            "             ReLU-10          [-1, 384, 16, 16]               0\n",
            "           Conv2d-11          [-1, 384, 16, 16]       1,327,488\n",
            "      BatchNorm2d-12          [-1, 384, 16, 16]             768\n",
            "             ReLU-13          [-1, 384, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 384, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         884,992\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "          Dropout-18                [-1, 16384]               0\n",
            "           Linear-19                 [-1, 1048]      17,171,480\n",
            "          Dropout-20                 [-1, 1048]               0\n",
            "           Linear-21                 [-1, 1048]       1,099,352\n",
            "           Linear-22                   [-1, 10]          10,490\n",
            "================================================================\n",
            "Total params: 21,605,802\n",
            "Trainable params: 21,605,802\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 13.96\n",
            "Params size (MB): 82.42\n",
            "Estimated Total Size (MB): 96.39\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "summary(net, input_size=(3, 32, 32))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkOyYt_TBjoT"
      },
      "source": [
        "## 3. モデルの学習\n",
        "### 3.1. 損失関数、最適化法(オプティマイザー)の定義\n",
        "- 損失関数は**nn.CrossEntropyLoss()**(ソフトマックス+交差エントロピー)を用います。\n",
        "- 最適化法には**optim.SGD(適用するモデルの重み、その他ハイパーパラメータの設定・・・)**を用います。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EsYsLJdyBjoU"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyXqyVoyBjoX"
      },
      "source": [
        "### 3.2. 学習の流れ(エポック単位)\n",
        "- ①画像データと正解ラベルを取り出す\n",
        "    - tqdmはjupyter内にプログレスバー(進行度)を表示する\n",
        "- ②画像データとラベルデータ(共にバッチ単位)をデバイス(GPU)に移動\n",
        "- ③勾配の初期化\n",
        "- ④モデルの推測(画像データ→各クラスである確率)\n",
        "- ⑤損失の計算\n",
        "- ⑥⑤で求めた損失をエポックでの累計損失に加える\n",
        "    - Tensorから値を取得する場合は、1次元(1要素)に指定してから.item()で取得する必要がある\n",
        "- ⑦正答率の計算(出力の最大値のインデックスが正解ラベルの場合1を出力をバッチサイズ分行う(.sum())\n",
        "    - (.maxは()で比較する値の軸を選び、[0]に最大値の値、[1]に最大値のインデックスを持つ)\n",
        "- ⑧逆伝搬の計算\n",
        "- ⑨勾配の更新<br>\n",
        "\n",
        "---全バッチで行う---\n",
        "- ⑩エポックでの平均誤差の計算\n",
        "- ⑪エポックでの平均正答率の計算\n",
        "- 検証データでの損失、精度を学習時と同じアルゴリズムで検証(逆伝搬、勾配の更新は行わない)\n",
        "\n",
        "*1:学習時には.train()で学習に関連する機能を有効にします。   \n",
        "*2:検証時には.eval()で学習に関連する機能を有効に、torch.no_grad()で自動微分を停止してから検証を行います。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516,
          "referenced_widgets": [
            "7e1df73c0ce7461ca51306ea0559cdf4",
            "367c4bfa30844860b62f624b0ddff71d",
            "8708feae9fea42168a31e1285ca259cb",
            "baf05b7decab408f9143d5f27a14a85b",
            "6ef8358030044d18a200bede11d2f453",
            "72b9324eb9374f8394b987a91bb26dd2",
            "1f644e033c1e46bdbfe86f7228087ef6",
            "f23c9e33a36b474aade183f1640ee5a4"
          ]
        },
        "id": "FnxAYcG8BjoY",
        "outputId": "597e0ce1-3b46-4a76-ef50-acf63ccfb3e3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7e1df73c0ce7461ca51306ea0559cdf4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=782.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-45c675e4ef65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#⑥\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mtrain_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#⑦\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#⑧\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#⑨\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "num_epochs = 20 #学習エポックの設定\n",
        "\n",
        "#グラフ作成のためにエポックごとの各値を保存する配列を作成\n",
        "train_loss_list = []\n",
        "train_acc_list = []\n",
        "val_loss_list = []\n",
        "val_acc_list = []\n",
        "\n",
        "#学習の定義\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = 0\n",
        "    train_acc = 0\n",
        "    val_loss = 0\n",
        "    val_acc = 0\n",
        "    i=0#学習回数\n",
        "    \n",
        "    net.train() #train *1\n",
        "    for (images, labels) in tqdm_notebook(train_loader): #①\n",
        "        images, labels = images.to(device), labels.to(device) #②\n",
        "        optimizer.zero_grad() #③\n",
        "        outputs = net(images) #④\n",
        "        loss = criterion(outputs, labels)#⑤\n",
        "        train_loss += loss.item()#⑥\n",
        "        train_acc += (outputs.max(1)[1] == labels).sum().item() #⑦\n",
        "        loss.backward()#⑧\n",
        "        optimizer.step()#⑨\n",
        "    \n",
        "    avg_train_loss = train_loss / len(train_loader.dataset) #⑩\n",
        "    avg_train_acc = train_acc / len(train_loader.dataset)   #⑪\n",
        "    \n",
        "    net.eval() #val *2\n",
        "    with torch.no_grad():#自動微分停止 *2\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = net(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            val_acc += (outputs.max(1)[1] == labels).sum().item()\n",
        "        avg_val_loss = val_loss / len(test_loader.dataset)\n",
        "        avg_val_acc = val_acc / len(test_loader.dataset)\n",
        "    \n",
        "        print ('Epoch [{}/{}], Loss: {loss:.4f}, val_loss: {val_loss:.4f}, val_acc: {val_acc:.4f}' \n",
        "                   .format(epoch+1, num_epochs, i+1, loss=avg_train_loss, val_loss=avg_val_loss, val_acc=avg_val_acc))\n",
        "        #グラフ壁画用に各値を配列に格納\n",
        "        train_loss_list.append(avg_train_loss)\n",
        "        train_acc_list.append(avg_train_acc)\n",
        "        val_loss_list.append(avg_val_loss)\n",
        "        val_acc_list.append(avg_val_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAbATIl2Bjob"
      },
      "source": [
        "## 4. 学習記録のグラフ化\n",
        "- matplotlibを用います。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zlc4MPFzBjod"
      },
      "outputs": [],
      "source": [
        "#学習のグラフ化\n",
        "plt.figure()\n",
        "plt.plot(range(num_epochs), train_loss_list, color='blue', linestyle='-', label='train_loss')\n",
        "plt.plot(range(num_epochs), val_loss_list, color='green', linestyle='--', label='val_loss')\n",
        "plt.legend()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.grid()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(range(num_epochs), train_acc_list, color='blue', linestyle='-', label='train_acc')\n",
        "plt.plot(range(num_epochs), val_acc_list, color='green', linestyle='--', label='val_acc')\n",
        "plt.legend()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.grid()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQE7nBI8Bjog"
      },
      "source": [
        "## 5. モデルのセーブ・ロード\n",
        "### 5.1. モデルのセーブ\n",
        "- モデルの保存は**(torch.save(model.state_dict,保存先のパス)**で行います。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4jils6OBjoh"
      },
      "outputs": [],
      "source": [
        "torch.save(net.state_dict(),\"net.ckpt\")#モデルの保存"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymlMzXdTBjok"
      },
      "source": [
        "### 5.2. モデルのロード\n",
        "- モデルの読み込みは**model.load_state_dict(torch.load(読み込み先のパス))**で行います。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MeBEjclTBjol"
      },
      "outputs": [],
      "source": [
        "#学習済みモデルを使用する場合はモデルをロード(CPUで実行する場合。GPU実行時はmap_location...は不要)\n",
        "net.load_state_dict(torch.load(\"./net.ckpt\",map_location=torch.device('cpu')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYwNXFOWBjon"
      },
      "source": [
        "## 6. モデルを用いたクラス認識予測デモ\n",
        "### 6.1. 予測する画像(猫の背景部分を切り取った画像)の読み込み、前処理\n",
        "- 画像の読み込み(JpegImageFile)・前処理にはPILライブラリのImageクラスを用います。\n",
        "    - モデルの入力サイズに画像をリサイズします。\n",
        "- モデルの入力サイズはバッチ単位なので**Tensor.unsqueeze(追加する軸の位置)**でバッチの次元を追加します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ydhwm_u-Bjoo"
      },
      "outputs": [],
      "source": [
        "image_path=r\"./cat_trim.jpg\"\n",
        "img = Image.open(image_path)\n",
        "img = img.resize((32, 32))\n",
        "plt.imshow(img)\n",
        "img=transforms.ToTensor()(img)\n",
        "img=img.unsqueeze(0)\n",
        "print(img.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yq167D4FBjor"
      },
      "source": [
        "### 6.2. モデルによるクラス予測(猫の背景部分を切り取った画像)\n",
        "- label_nameはモデルの出力インデックスに対応するクラス名を定義しています。\n",
        "- **nn.Softmax(値の軸)**で得られた出力を合計で1となるような確率に変換します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1omwF9DBjot"
      },
      "outputs": [],
      "source": [
        "net.eval()\n",
        "with torch.no_grad():\n",
        "    #output=net(img.cuda())\n",
        "    img.to(device)\n",
        "    output=net(img)\n",
        "    output=output.cpu()\n",
        "    label_name=[\"airplane\",\"automobile\",\"bird\",\"cat\",\"deer\",\"dog\",\"frog\",\"horse\",\"ship\",\"truck\"] \n",
        "    output_probability=nn.Softmax(0)(output[0])\n",
        "    for i in range(0,9):\n",
        "        print(label_name[i],\"である確率は\",output_probability[i].item(),\"です\")\n",
        "    predict_label=output.max(1)[1]\n",
        "    print(\"入力した画像のクラスは\",label_name[predict_label.item()],\"です\")\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKFyOPjQBjow"
      },
      "source": [
        "### 6.3. 予測する画像(猫の原画像)の読み込み、前処理"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rG7YuFRIBjox"
      },
      "outputs": [],
      "source": [
        "image_path=r\"./cat_origin.jpg\"\n",
        "img = Image.open(image_path)\n",
        "img = img.resize((32, 32))\n",
        "plt.imshow(img)\n",
        "img=transforms.ToTensor()(img)\n",
        "img=img.unsqueeze(0)\n",
        "print(img.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJJieyEpBjo0"
      },
      "source": [
        "### 6.4. モデルによるクラス予測(猫の背景部分を切り取った画像)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjrohhvbBjo0"
      },
      "outputs": [],
      "source": [
        "net.eval()\n",
        "with torch.no_grad():\n",
        "    #output=net(img.cuda())\n",
        "    img.to(device)\n",
        "    output=net(img)\n",
        "    output=output.cpu()\n",
        "    output_probability=nn.Softmax(0)(output[0])\n",
        "    for i in range(0,9):\n",
        "        print(label_name[i],\"である確率は\",output_probability[i].item(),\"です\")\n",
        "    predict_label=output.max(1)[1]\n",
        "    print(\"入力した画像のクラスは\",label_name[predict_label.item()],\"です\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AGZN9XFBjo3"
      },
      "source": [
        "## 7. モデルの中間出力の可視化\n",
        "### 7.1. モデルの中間出力\n",
        "- nn.Moduleを継承したクラスで定義されたモデルでは__init__関数で定義したネットワーク層を個別に取り出すことができます。\n",
        "    - 入力を逐次的にそれぞれのネットワーク層へ伝搬していくことでそれぞれのネットワーク層の出力を得ています。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EvDp14AdBjo3"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    #ブロック毎の中間出力を得ていく\n",
        "    img.to(device)\n",
        "    #output1=net.block1(img.cuda())\n",
        "    output1=net.block1(img)\n",
        "    output2=net.block2(output1)\n",
        "    output3=net.block3(output2)\n",
        "    output4=net.block4(output3)\n",
        "    output5=net.block5(output4)\n",
        "    #出力をCPUへ\n",
        "    output1=output1.cpu()\n",
        "    output2=output2.cpu()\n",
        "    output3=output3.cpu()\n",
        "    output4=output4.cpu()\n",
        "    output5=output5.cpu()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65LHN-FIBjo6"
      },
      "source": [
        "### 7.2. 中間出力の壁画設定\n",
        "- mataplotlibを用いて壁画します。\n",
        "- 中間出力をを1チャンネルずつ出力するのでグレースケールで壁画します。\n",
        "- pylabライブラリのrcParamsクラスを用いることで壁画サイズを10倍に拡大しています。\n",
        "- output_image関数は引数のネットワーク層での中間出力を10種類壁画する関数です。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76HwOSnEBjo7"
      },
      "outputs": [],
      "source": [
        "plt.gray()#グレースケールで表示(フィルタは1チャンネルで表示)\n",
        "rcParams['figure.figsize'] = 10,10#10倍拡大\n",
        "\n",
        "def output_image(output,block_num):\n",
        "    output=output.numpy()\n",
        "    for i in range(0,10):\n",
        "        ax=plt.subplot(5,10,10*(block_num-1)+(i+1))#5*10個に領域分けしたうちの5*(ブロック数-11)*(i+1)個目を選択\n",
        "        # 目盛りを無くす。\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "        plt.imshow(output[0][i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6VAwDyhBjo-"
      },
      "source": [
        "### 7.3. 中間出力の壁画\n",
        "- output_image関数を用います。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uBEl_mW3Bjo_",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "output_image(output1,1)\n",
        "output_image(output2,2)\n",
        "output_image(output3,3)\n",
        "output_image(output4,4)\n",
        "output_image(output5,5)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "pytorch_cnn.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "056b1a5f2c3340edbdf2d7c9b094c8dc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f644e033c1e46bdbfe86f7228087ef6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "367c4bfa30844860b62f624b0ddff71d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5291cc5a45484153900e7c9658477e75": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ef8358030044d18a200bede11d2f453": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "7074fa6a34564802ab1239a254f90bf6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72b9324eb9374f8394b987a91bb26dd2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76746f7c45754c57ab78ea081107b4c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7074fa6a34564802ab1239a254f90bf6",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_da2b2f4c59b94d868c1064e56fca8a73",
            "value": 170498071
          }
        },
        "7e1df73c0ce7461ca51306ea0559cdf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8708feae9fea42168a31e1285ca259cb",
              "IPY_MODEL_baf05b7decab408f9143d5f27a14a85b"
            ],
            "layout": "IPY_MODEL_367c4bfa30844860b62f624b0ddff71d"
          }
        },
        "8708feae9fea42168a31e1285ca259cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "  0%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72b9324eb9374f8394b987a91bb26dd2",
            "max": 782,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6ef8358030044d18a200bede11d2f453",
            "value": 1
          }
        },
        "8d33bbf004524bfa83982c489c6bfefa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_76746f7c45754c57ab78ea081107b4c1",
              "IPY_MODEL_b317994d1c664e45931b198c4a0801e3"
            ],
            "layout": "IPY_MODEL_056b1a5f2c3340edbdf2d7c9b094c8dc"
          }
        },
        "b317994d1c664e45931b198c4a0801e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5291cc5a45484153900e7c9658477e75",
            "placeholder": "​",
            "style": "IPY_MODEL_d36b415a75e344eb8774763b86956b51",
            "value": " 170499072/? [00:07&lt;00:00, 23518015.16it/s]"
          }
        },
        "baf05b7decab408f9143d5f27a14a85b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f23c9e33a36b474aade183f1640ee5a4",
            "placeholder": "​",
            "style": "IPY_MODEL_1f644e033c1e46bdbfe86f7228087ef6",
            "value": " 1/782 [00:16&lt;3:39:34, 16.87s/it]"
          }
        },
        "d36b415a75e344eb8774763b86956b51": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da2b2f4c59b94d868c1064e56fca8a73": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "f23c9e33a36b474aade183f1640ee5a4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
